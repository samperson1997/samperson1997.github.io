<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Blog of Samperson">
  <meta name="keyword" content="">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      决策树——Sklearn库实现 | Blog of Samperson
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
</head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Blog of Samperson</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
    <h2>
        决策树——Sklearn库实现
    </h2>
    <p class="post-date">
        2018-06-18
    </p>
    <div class="arrow-down">
        <a href="javascript:;"></a>
    </div>
</div>
<main class="app-body flex-box">
    <!-- Article START -->
    <article class="post-article">
        <section class="markdown-content">
            <h2 id="决策树简介"><a href="#决策树简介" class="headerlink" title="决策树简介"></a>决策树简介</h2><table>
<thead>
<tr>
<th></th>
<th style="text-align:left">输入</th>
<th style="text-align:left">输出</th>
<th style="text-align:left">适用的数据集</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>决策树</td>
<td style="text-align:left">决策树+用于构造树的所有类标签向量执行分类</td>
<td style="text-align:left">决策结果</td>
<td style="text-align:left">适合处理有缺失属性的高维数据样本；对于各类别样本数量不一致的数据，信息增益的结果偏向于那些具有更多数值的特征。</td>
<td style="text-align:left">不支持在线学习，在新样本到来后，决策树需要全部重建；容易出现过拟合。<br>计算简单，易于理解，可解释性强；能够处理不相关的特征；在相对短的时间内能够对大型数据源做出可行且效果良好的结果；忽略了数据之间的相关性。</td>
</tr>
</tbody>
</table>
<p>[1] 决策树是一个非参数的监督式学习方法，主要用于分类和回归。算法的目标是通过推断数据特征，学习决策规则从而创建一个预测目标变量的模型。<br>[2] DecisionTreeClassifier 能够实现多类别的分类。<br>[3] <strong>输入两个向量：向量X，大小为[n_samples, n_features]，用于记录训练样本；<br>向量Y，大小为[n_samples]，用于存储训练样本的类标签。</strong></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">Y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">clf = tree.DecisionTreeClassifier().fit(X, Y)</span><br><span class="line"></span><br><span class="line">clf.predict([[<span class="number">2.</span>, <span class="number">2.</span>]]) <span class="comment"># 用来预测分类</span></span><br><span class="line">clf.predict_proba([[<span class="number">2.</span>, <span class="number">2.</span>]])  <span class="comment"># 每个分类的概率可以被预测，即某个叶子中该分类样本的占比</span></span><br></pre></td></tr></table></figure>
<h2 id="重要的参数"><a href="#重要的参数" class="headerlink" title="重要的参数"></a>重要的参数</h2><p>[1] criterion，节点分割标准，规定了该决策树所采用的的最佳分割属性的判决方法，有两种：“gini”（默认按照GINI基尼系数分割），“entropy”（使用信息熵作为划分标准）。<br><br><br>[2] min_weight_fraction_leaf，限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起分割。<br>默认是0——不考虑权重问题<br>有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重——注意这个值。<br><br><br>[3]-[7]</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:left">样本量不大</th>
<th style="text-align:left">样本量大</th>
</tr>
</thead>
<tbody>
<tr>
<td>splitter</td>
<td style="text-align:left">默认best，在特征的所有划分点中找出最优的划分点</td>
<td style="text-align:left">random，随机的在部分划分点中找局部最优的划分点</td>
</tr>
<tr>
<td>max_features，划分时考虑的最大特征数</td>
<td style="text-align:left">默认是None，节点会一直扩展直到全部分开，或者小于min_samples_split samples设定值</td>
<td style="text-align:left">推荐限制最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间</td>
</tr>
<tr>
<td>max_depth，限定了决策树的最大深度，对于防止过拟合非常有用</td>
<td style="text-align:left">默认是None，节点会一直扩展直到全部分开，或者小于min_samples_split samples设定值</td>
<td style="text-align:left">推荐限制最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间</td>
</tr>
<tr>
<td>min_samples_split，内部节点再划分所需样本数目，除了整数外，也可以设置成样本数目的百分比</td>
<td style="text-align:left">默认是2</td>
<td style="text-align:left">推荐增大这个值</td>
</tr>
<tr>
<td>min_samples_leaf，限定了叶子节点包含的最小样本数，如果某子节点进行划分后的叶子节点所含样本数少于该给定值，则停止该子节点的划分，否则继续划分</td>
<td style="text-align:left">默认是1</td>
<td style="text-align:left">推荐增大这个值</td>
</tr>
</tbody>
</table>
<p><br><br>[8] max_leaf_nodes，最大叶子节点数。默认是None，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。<br>特征不多——不考虑这个值<br>特征多的话——加以限制，具体的值可以通过交叉验证得到。<br><br><br>[9] class_weight，类别权重，指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多，导致训练的决策树过于偏向这些类别<br>balanced——算法会自己计算权重，样本量少的类别所对应的样本权重会高。<br>默认的None——如果你的样本类别分布没有明显的偏倚，则可以不管这个参数<br>自己指定各个样本的权重<br>回归树：不适用回归树<br><br><br>[10] random_state<br>int——random_state是随机数字发生器的种子<br>RandomState——random_state是随机数字发生器<br>None——随机数字发生器是np.random使用的RandomState instance<br><br><br>[11] min_impurity_split，最小不纯度值分割，提前停止的应用策略，一个节点只有其不纯度值大于该阈值时才会被分割，否则该节点为叶子结点，不再分割。<br><br><br>[12] presort，样本是否预排序，默认是False不排序。一般来说，如果样本量少或者限制了一个深度很小的决策树，设置为true可以让划分点选择更加快，决策树建立的更加快。如果样本量太大的话，反而没有什么好处。一般不用设置。</p>
<h2 id="重要的属性方法"><a href="#重要的属性方法" class="headerlink" title="重要的属性方法"></a>重要的属性方法</h2><p>[1] n_classes_：决策树中的类数量。<br>[2] classes_：返回决策树中的所有种类标签。<br>[3] feature_importances_：特征重要度，值越大那么越重要。<br>[4] n_features_：Fit函数产生的特征数目<br>[5] n_outputs_：Fit函数输出结果数目<br>[6] tree_：产生的树对象</p>
<h2 id="重要的方法"><a href="#重要的方法" class="headerlink" title="重要的方法"></a>重要的方法</h2><p>[1] predict(X)：送入样本X，得到决策树的预测。可以同时送入多个样本。<br>[2] transform(X, threshold=None)：返回X的较重要的一些feature，相当于裁剪数据。<br>[3] score(X, y, sample_weight=None)：返回在数据集X,y上的测试分数，正确率。<br>[4] fit(X, y, sample_mask=None, X_argsorted=None, check_input=True, sample_weight=None) ：将数据集x，和标签集y送入分类器进行训练，这里要注意一个参数是：sample_weright，它和样本的数量一样长，所携带的是每个样本的权重。<br>[5] get_params(deep=True)：得到决策树的各个参数。<br>[6] set_params(**params)：调整决策树的各个参数。</p>
<h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><p>[1] 当数据中的feature较多时，一定要有足够的数据量来支撑算法，不然的话很容易过拟合<br>[2] PCA是一种避免高维数据过拟合的办法<br>[3] 从一棵较小的树开始探索，用export方法打印出来看看。<br>[4] 善用max_depth参数，缓慢的增加并测试模型，找出最好的那个depth<br>[5] 善用min_samples_split和min_samples_leaf参数来控制叶子节点的样本数量，防止过拟合<br>[6] 平衡训练数据中的各个种类的数据，防止一个种类的数据dominate</p>
<h2 id="官网示例代码"><a href="#官网示例代码" class="headerlink" title="官网示例代码"></a>官网示例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">n_classes = <span class="number">3</span></span><br><span class="line">plot_colors = <span class="string">"bry"</span></span><br><span class="line">plot_step = <span class="number">0.02</span></span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pairidx, pair <span class="keyword">in</span> enumerate([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">                                [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>]]):</span><br><span class="line">    X = iris.data[:, pair]</span><br><span class="line">    y = iris.target</span><br><span class="line"></span><br><span class="line">    clf = DecisionTreeClassifier().fit(X, y)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, pairidx + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),</span><br><span class="line">                         np.arange(y_min, y_max, plot_step))</span><br><span class="line"></span><br><span class="line">    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(iris.feature_names[pair[<span class="number">0</span>]])</span><br><span class="line">    plt.ylabel(iris.feature_names[pair[<span class="number">1</span>]])</span><br><span class="line">    plt.axis(<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, color <span class="keyword">in</span> zip(range(n_classes), plot_colors):</span><br><span class="line">        idx = np.where(y == i)</span><br><span class="line">        plt.scatter(X[idx, <span class="number">0</span>], X[idx, <span class="number">1</span>], c=color, label=iris.target_names[i],</span><br><span class="line">                    cmap=plt.cm.Paired)</span><br><span class="line"></span><br><span class="line">    plt.axis(<span class="string">"tight"</span>)</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">"Decision surface of a decision tree using paired features"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><p>[1] ID3（Iterative Dichotomiser 3，迭代二叉树 第3代）创建了一个多叉树，并（以一种贪婪的方式）寻找每个节点上的分类特征，并为分类目标获取出最大的信息收益。一般这种算法生成的树都会”生长”到最大尺寸，所以经常需要一个修剪阶段来提高其应用在新数据上的能力。<br>[2] C4.5 是 ID3 算法的后继者，它通过动态地定义离散参数（基于数值变量），将连续的属性值转化为一组间距离散来取消特征必须是分类型的这一约束条件。C4.5将经过训练的树（即经过ID3算法输出的多叉树）转化为一个”如果…即…”的规则组。然后这些规则组将会通过评估后，以确定其排序位置。如果树的准确度没有提高，那么将会通过去除一些规则来完成修剪操作。<br>[3] C5.0 是昆兰根据其所有权下对该算法的最新版本。比起C4.5，它占用的内存更少，建立出的规则组规模更小，但精准度更高。<br>[4] CART（Classification and Regression Trees，分类与回归树）跟 C4.5 相比很相似，但是其不同点在于它（在回归问题）支持数值的目标变量和不需要计算规则组。CART 通过在每个节点上使用特征和阈值来产生出最大的信息收益。<br><strong>scikit-learn中使用的CART算法是经过优化后的版本。</strong></p>
<h2 id="交叉参见"><a href="#交叉参见" class="headerlink" title="交叉参见"></a>交叉参见</h2><p><a href="https://samperson1997.github.io/2018/06/03/classification-algorithm/" title="适于二分类的机器学习算法" target="_blank" rel="noopener">适于二分类的机器学习算法</a>，<a href="https://samperson1997.github.io/2018/06/24/svm/" title="SVM" target="_blank" rel="noopener">SVM</a>，<a href="https://samperson1997.github.io/2018/07/01/cnn/" title="卷积神经网络" target="_blank" rel="noopener">卷积神经网络</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier</a><br>[2] <a href="https://www.cnblogs.com/zhaoxy/p/5054938.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhaoxy/p/5054938.html</a><br>[3] <a href="https://www.cnblogs.com/AlwaysT-Mac/p/6647192.html" target="_blank" rel="noopener">https://www.cnblogs.com/AlwaysT-Mac/p/6647192.html</a><br>[4] <a href="https://blog.csdn.net/lihou1987/article/details/71125145" target="_blank" rel="noopener">https://blog.csdn.net/lihou1987/article/details/71125145</a><br>[5] <a href="https://www.jianshu.com/p/0724dde480f0" target="_blank" rel="noopener">https://www.jianshu.com/p/0724dde480f0</a></p>

        </section>
        <!-- Tags START -->
        
            <div class="tags">
                <span>Tags:</span>
                
  <a href="/tags#机器学习" >
    <span class="tag-code">机器学习</span>
  </a>

            </div>
            
                <!-- Tags END -->
                <!-- 打赏 START -->
                
                    <div class="money-like">
                        <div class="reward-btn">
                            赏
                            <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
                            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
                            </span>
                        </div>
                        <p class="notice">如果觉得我的文章对您有帮助，欢迎点击上方按钮对我打赏</p>
                    </div>
                    
                        <!-- 打赏 END -->
                        <!-- 二维码 START -->
                        
                                <!-- 二维码 END -->
                                
                                    <!-- Gitment START -->
                                    <div id="comments"></div>
                                    <!-- Gitment END -->
                                    
    </article>
    <!-- Article END -->
    <!-- Catalog START -->
    
        <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#决策树简介"><span class="toc-nav-text"><a href="#&#x51B3;&#x7B56;&#x6811;&#x7B80;&#x4ECB;" class="headerlink" title="&#x51B3;&#x7B56;&#x6811;&#x7B80;&#x4ECB;"></a>&#x51B3;&#x7B56;&#x6811;&#x7B80;&#x4ECB;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Demo"><span class="toc-nav-text"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#重要的参数"><span class="toc-nav-text"><a href="#&#x91CD;&#x8981;&#x7684;&#x53C2;&#x6570;" class="headerlink" title="&#x91CD;&#x8981;&#x7684;&#x53C2;&#x6570;"></a>&#x91CD;&#x8981;&#x7684;&#x53C2;&#x6570;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#重要的属性方法"><span class="toc-nav-text"><a href="#&#x91CD;&#x8981;&#x7684;&#x5C5E;&#x6027;&#x65B9;&#x6CD5;" class="headerlink" title="&#x91CD;&#x8981;&#x7684;&#x5C5E;&#x6027;&#x65B9;&#x6CD5;"></a>&#x91CD;&#x8981;&#x7684;&#x5C5E;&#x6027;&#x65B9;&#x6CD5;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#重要的方法"><span class="toc-nav-text"><a href="#&#x91CD;&#x8981;&#x7684;&#x65B9;&#x6CD5;" class="headerlink" title="&#x91CD;&#x8981;&#x7684;&#x65B9;&#x6CD5;"></a>&#x91CD;&#x8981;&#x7684;&#x65B9;&#x6CD5;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#使用建议"><span class="toc-nav-text"><a href="#&#x4F7F;&#x7528;&#x5EFA;&#x8BAE;" class="headerlink" title="&#x4F7F;&#x7528;&#x5EFA;&#x8BAE;"></a>&#x4F7F;&#x7528;&#x5EFA;&#x8BAE;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#官网示例代码"><span class="toc-nav-text"><a href="#&#x5B98;&#x7F51;&#x793A;&#x4F8B;&#x4EE3;&#x7801;" class="headerlink" title="&#x5B98;&#x7F51;&#x793A;&#x4F8B;&#x4EE3;&#x7801;"></a>&#x5B98;&#x7F51;&#x793A;&#x4F8B;&#x4EE3;&#x7801;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#决策树算法"><span class="toc-nav-text"><a href="#&#x51B3;&#x7B56;&#x6811;&#x7B97;&#x6CD5;" class="headerlink" title="&#x51B3;&#x7B56;&#x6811;&#x7B97;&#x6CD5;"></a>&#x51B3;&#x7B56;&#x6811;&#x7B97;&#x6CD5;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#交叉参见"><span class="toc-nav-text"><a href="#&#x4EA4;&#x53C9;&#x53C2;&#x89C1;" class="headerlink" title="&#x4EA4;&#x53C9;&#x53C2;&#x89C1;"></a>&#x4EA4;&#x53C9;&#x53C2;&#x89C1;</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#参考资料"><span class="toc-nav-text"><a href="#&#x53C2;&#x8003;&#x8D44;&#x6599;" class="headerlink" title="&#x53C2;&#x8003;&#x8D44;&#x6599;"></a>&#x53C2;&#x8003;&#x8D44;&#x6599;</span></a></li></ol>
    
  </div>
</aside>
            
                <!-- Catalog END -->
</main>

<script>
    (function() {
        var url = 'http://yoursite.com/2018/06/18/decision-tree/';
        var banner = 'https://images.pexels.com/photos/2470678/pexels-photo-2470678.jpeg?h=1280&w=1921'
        if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
            $('#article-banner').css({
                'background-image': 'url(' + banner + ')'
            })
        } else {
            $('#article-banner').geopattern(url)
        }
        $('.header').removeClass('fixed-header')

        // error image
        $(".markdown-content img").on('error', function() {
            $(this).attr('src', 'http://file.muyutech.com/error-img.png')
            $(this).css({
                'cursor': 'default'
            })
        })

        // zoom image
        $(".markdown-content img").on('click', function() {
            var src = $(this).attr('src')
            if (src !== 'http://file.muyutech.com/error-img.png') {
                var imageW = $(this).width()
                var imageH = $(this).height()

                var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
                zoom = zoom < 1 ? 1 : zoom
                zoom = zoom > 2 ? 2 : zoom
                var transY = (($(window).height() - imageH) / 2).toFixed(2)

                $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="' + src + '" /></div></div>')
                $('.image-view-wrap').addClass('wrap-active')
                $('.image-view-wrap img').css({
                    'width': `${imageW}`,
                    'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
                })
                $('html').css('overflow', 'hidden')

                $('.image-view-wrap').on('click', function() {
                    $(this).remove()
                    $('html').attr('style', '')
                })
            }
        })

        // qrcode
        var qr = new QRious({
            element: document.getElementById('share-qrcode'),
            value: document.location.href
        });

        // gitment
        var gitmentConfig = "samperson1997";
        if (gitmentConfig !== 'undefined') {
            var gitment = new Gitment({
                id: "决策树——Sklearn库实现",
                owner: "samperson1997",
                repo: "samperson1997.github.io",
                oauth: {
                    client_id: "fa0bf61cc2d9eb136c1a",
                    client_secret: "81df51391c08edc497b6bb434029521c92ea19fd"
                },
                theme: {
                    render(state, instance) {
                        const container = document.createElement('div')
                        container.lang = "en-US"
                        container.className = 'gitment-container gitment-root-container'
                        container.appendChild(instance.renderHeader(state, instance))
                        container.appendChild(instance.renderEditor(state, instance))
                        container.appendChild(instance.renderComments(state, instance))
                        container.appendChild(instance.renderFooter(state, instance))
                        return container;
                    }
                }
            })
            gitment.render(document.getElementById('comments'))
        }
    })();

</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
    <p class="copyright">
        &copy;
        2019 | Content by <a href="https://samperson1997.github.io/about/">Samperson</a> | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
            <br> Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
    </p>
</footer>

<script>
    function async(u, c) {
        var d = document,
            t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) {
            o.addEventListener('load', function(e) {
                c(null, e);
            }, false);
        }
        s.parentNode.insertBefore(o, s);
    }

</script>
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function() {
        FastClick.attach(document.body);
    })

</script>

<script>
    var hasLine = 'true';
    async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function() {
        $('figure pre').each(function(i, block) {
            var figure = $(this).parents('figure');
            if (hasLine === 'false') {
                figure.find('.gutter').hide();
            }
            var lang = figure.attr('class').split(' ')[1] || 'code';
            var codeHtml = $(this).html();
            var codeTag = document.createElement('code');
            codeTag.className = lang;
            codeTag.innerHTML = codeHtml;
            $(this).attr('class', '').empty().html(codeTag);
            figure.attr('data-lang', lang.toUpperCase());
            hljs.highlightBlock(block);
        });
    })

</script>
<!-- Baidu Tongji -->

        <script src="/js/script.js"></script>

  </body>
</html>